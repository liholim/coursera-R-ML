---
title: "Evaluating Exercise Technique using Machine Learning"
output: html_document
---

## Introduction

From the paper *Qualitative Activity Recognition of Weight Lifting Exercises*, accelerometers were attached to participants on various body parts as they performed dumbbell movements correctly and incorectly in 5 different ways. We use the dataset generated by their work to build a Random Forest classification model and predict the class of movement based on the accelerometer measurements.

## Importing and Cleaning Data

After importing the data, data that was typecast as factor was typecast to numeric. Data in the test set which were entirely NA were removed from the training set to avoid having to impute. Additionally, identifying information not related to the measurements of the movements, such as user_name and timestamp, were removed from the training data as they were not relevant and could feed false information.

```{r import, cache=TRUE}
library(caret)
set.seed(100)
train <- read.csv(url('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'))
test <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
library(dplyr)
train[,-160] <- train[,-160] %>% mutate_if(is.factor, as.numeric)
na_count <- sapply(test %>% select(-problem_id),
                   function(y) sum(length(which(is.na(y)))))
train <- train %>% select(append(names(na_count[na_count == 0]), 'classe')) %>%
                   select(-X, -user_name, -contains('timestamp'),
                          -contains('window'))
test <- test %>% mutate_if(is.factor, as.numeric) %>%
                 select(names(na_count[na_count == 0])) %>%
                 select(-X, -user_name, -contains('timestamp'),
                        -contains('window'))
```

## Building the Model

A random forest was selected for the model for it's strength in classification. The data was preprocessed using centering, scaling, Yeo-Johnson Transformation, removal of near zero variance predictors, and principal component analysis for 95% of explained variation. A 10-fold cross validation was used for the resampling method as a middle ground between accurate model training and excessive model training time. 

```{r model, cache=TRUE}
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method='cv', number=10, allowParallel=TRUE)
fitrf <- train(classe~., data=train, method='rf',
               preProcess=c('center', 'scale', 'YeoJohnson', 'nzv', 'pca'),
               trControl=fitControl)
stopCluster(cluster)
registerDoSEQ()
```

## Results

The final model correctly predicted 19 of 20 of the test cases.

```{r test, cache=TRUE}
predrf <- predict(fitrf, test)
print(data.frame(predrf))
print(fitrf)
```

## Use of Cross Validation

10-fold Cross validation was used to perform multiple evaluations of different model tuning parameters and estimate the error rate for each. The tuning parameter evaluated for this model was the number of variables randomly sampled as candidates for each split; the values evaluated were 2, 27, and 52. The tuning parameter value with the highest accuracy was selected as the final model.

## Estimation of Out of Sample Error

The accuracy of the final model is 98.33% and the Kappa is 97.89%. The Out of Sample Error is estimated to be greater than the In-Sample error of the model; so the Out of Sample Accuracy and Kappa is estimated to be less than the In-Sample Accuracy and Kappa of 98.33% and 97.89%.
